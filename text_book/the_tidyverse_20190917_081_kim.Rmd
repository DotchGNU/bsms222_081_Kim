---
title: "Chap5_The_tidyverse"
output: html_notebook
---

* * *

# 5.0 vector to data frame 

Up to now we have been manipulating vectors by **reordering** and **subsetting** them through **indexing**. However, once we start more advanced analyses, the _preferred unit for data storage is not the vector_ but the **data frame**. In this chapter we learn to work directly with **data frames**, which greatly facilitate the organization of information.. We will be using data frames for the majority of this book. We will focus on a specific data format referred to as tidy and on specific collection of packages that are particularly helpful for working with _tidy_ data referred to as the `tidyverse`.

We can load all the tidyverse packages at once by installing and loading the tidyverse package:

```{r}
#install.packages("tidyverse")
library(tidyverse)
```

###### >> conlicts : name space가 겹친 경우 (chap4 참고, {package_name}::{function_name})

We will learn how to implement the tidyverse approach throughout the book, but before delving into the details, in this chapter we introduce some of the most widely used tidyverse functionality. starting with the `dplyr` package for **manipulating data frames** and the `purrr` package for **working with functions**. Note that the tidyverse also includes a **graphing package**, `ggplot2`, which we introduce later in Chapter 8 in the Data Visualization part of the book; the `readr` package discussed in Chapter 6; and many others. In this chapter, we first introduce the **concept of tidy data** and then demonstrate how we use the tidyverse to work with data frames in this format.

> major packages in `tidyverse`

1. `dplyr` : manipulating data frames
2. `purrr` : working with function (we already use `gsup` function)
3. `ggplot2` : graphing package (chap8)
4. `readr` : importing module 


* * *

# 5.1 Tidy data

We say that a data table is in tidy format if each **row** represents _one observation_ and **columns** represent the _different variables_ available for each of these observations. The `murders` dataset is an example of a tidy data frame.

``` 
tidy data 
1. each raw >> one observation
2. each column >> different variables 
```

```{r}
#>        state abb region population total
#> 1    Alabama  AL  South    4779736   135
#> 2     Alaska  AK   West     710231    19
#> 3    Arizona  AZ   West    6392017   232
#> 4   Arkansas  AR  South    2915918    93
#> 5 California  CA   West   37253956  1257
#> 6   Colorado  CO   West    5029196    65
```


Each row represent a state with each of the five columns providing a different variable related to these states: name, abbreviation, region, population, and total murders.

To see how the same information can be provided in different formats, consider the following example:

```{r}
#>        country year fertility
#> 1      Germany 1960      2.41
#> 2  South Korea 1960      6.16
#> 3      Germany 1961      2.44
#> 4  South Korea 1961      5.99
#> 5      Germany 1962      2.47
#> 6  South Korea 1962      5.79
#> 7      Germany 1963      2.49
#> 8  South Korea 1963      5.57
#> 9      Germany 1964      2.49
#> 10 South Korea 1964      5.36
#> 11     Germany 1965      2.48
#> 12 South Korea 1965      5.16
```

```
Q) Does each columns seperated by tap or space? maybe tap..? I'm not sure. 
```

This tidy dataset provides fertility rates for two countries across the years. This is a tidy dataset because each row presents one observation with the three variables being county, year and fertility rate. However, this dataset originally came in another format and was **reshaped** for the `dslabs` package. Originally, the data was in the following format:

```{r}
#>       country 1960 1961 1962 1963 1964 1965
#> 1     Germany 2.41 2.44 2.47 2.49 2.49 2.48
#> 2 South Korea 6.16 5.99 5.79 5.57 5.36 5.16
```

The same information is provided, but there are two important differences in the format: 

> 1) each row includes several observations and 
> 2) one of the variables, year, is stored in the header. 

For the tidyverse packages to be optimally used, data need to be **reshaped into tidy format**, which you will learn to do in the **Data Wrangling** part of the book. Until then, we will use example datasets that are already in tidy format.

```
Data Warngling(=Data munging) : Transforming and mapping from one "raw" data form into another format. 
Data Parsing(=syntax analysis) : Analysing a string of symbols conforming to the rules of a formal grammar and making the parse tree.
** parse = part (of speech)
```

Although not immediately obvious, as you go through the book you will start to appreciate the advantages of working in a framework in which functions use _tidy formats for both inputs and outputs_. You will see how _this permits the data analyst to focus on more important aspects_ of the analysis rather than the format of the data.

* * *

# 5.2 Exercise

1. Examine the built-in dataset co2. Which of the following is true:

A. co2 is tidy data: it has one year for each row.

B. co2 is not tidy: we need at least one column with a character vector.

C. co2 is not tidy: it is a matrix instead of a data frame.

 _> isn't it correct?_

**D. co2 is not tidy: to be tidy we would have to wrangle it to have three columns (year, month and value), then each co2 observation would have a row.**


```{r}
data("co2")
co2
```

> each row : time series data of each year  
> each column : each month 

```{r}
# 왜 head(co2)는 header를 출력해주지 않는가? 
head(co2)
```

```{r}
class(co2)
# 1. dataframe이 아니기때문 
# 2. matrix (ts가 matrix의 일종인듯)로 인식되기 때문 
```
> ts : [time-series object](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/ts.html) 



2. Examine the built-in dataset ChickWeight. Which of the following is true:

A. ChickWeight is not tidy: each chick has more than one row.

**B. ChickWeight is tidy: each observation (a weight) is represented by one row. The chick from which this measurement came from is one the variables.**

C. ChickWeight is not a tidy: we are missing the year column.

D. ChickWeight is tidy: it is stored in a data frame.


```{r}
data("ChickWeight")
head(ChickWeight,10)
class(ChickWeight)
```



3. Examine the built-in dataset BOD. Which of the following is true:

A. BOD is not tidy: it only has six rows.

B. BOD is not tidy: the first column is just an index.

**C. BOD is tidy: each row is an observation with two values (time and demand)**

D. BOD is tidy: all small datasets are tidy by definition.


```{r}
data("BOD")
BOD
```



4. Which of the following built-in datasets is tidy (you can pick more than one):

A. BJsales

**B. EuStockMarkets**

**C. DNase**

**D. Formaldehyde**

**E. Orange**

F. UCBAdmissions


```{r}
data("BJsales",EuStockMarkets,DNase,Formaldehyde,Orange,UCBAdmissions)

head(BJsales)
head(EuStockMarkets)
head(DNase)
head(Formaldehyde)
head(Orange)
head(UCBAdmissions)
```

```{r}
#dataset_name = c(BJsales,EuStockMarkets,DNase,Formaldehyde,Orange,UCBAdmissions)
#for (i in dataset_name){
#  print(head(i,5))
#}
```


```
>> it's not working
1) dataset_name이라는 vector에 변수명을 string(""이용)으로 저장하는 경우 => 그저 string으로 for-loop을 돌게되어 무의미
2) string이 아니게 저장하는 경우 => 이상한 방식으로 for loop을 돎... 
>> 원인 : numeric이나 character가 아니고, data frame이나 matrix를 vector로 묶으려고 하면 list가 되어버림. 
 - 변수형에 따라 for-loop 실험해보기 
```


***

# 5.3 Manipulating data frames 

The `dplyr` package from the tidyverse introduces functions that perform some of the most common operations when working with data frames and uses names for these functions that are relatively easy to remember. For instance, to change the data table by adding a new column, we use `mutate`. To filter the data table to a subset of rows, we use `filter`. Finally, to subset the data by selecting specific columns, we use `select`.

1) `mutate` : change the data table by adding a new column
2) `filter` : filter the data table to a subset of rows 
3) `select` : subset the data by selecting specific columns 

## 5.3.1 Adding a column with `mutate`

We want all the necessary information for our analysis to be included in the data table. So the first task is to add the murder rates to our murders data frame. The function `mutate` takes the data frame as a first argument and the name and values of the variable as a second argument using the convention name = values. So, to add murder rates, we use:


```{r}
library(dslabs) #Data Science Labs 
data("murders")
head(murders)
```
```{r}
murders <- mutate(murders, rate = total / population * 100000)
head(murders)
# successfully insert the column 
```

Notice that here we used `total` and `population` inside the function, which are objects that _are not defined in our workspace._ But why don’t we get an error?

This is one of `dplyr`’s main features. Functions in this package, such as `mutate`, know to look for variables in the data frame provided in the **first argument**. In the call to `mutate` above, total will have the values in murders$total. This approach makes the code much more **readable**.

```
* dplyr는 data frame의 first argument를 일종의 변수명으로 인식한다. 
```

We can see that the new column is added:
```{r}
head(murders)
#>        state abb region population total rate
#> 1    Alabama  AL  South    4779736   135 2.82
#> 2     Alaska  AK   West     710231    19 2.68
#> 3    Arizona  AZ   West    6392017   232 3.63
#> 4   Arkansas  AR  South    2915918    93 3.19
#> 5 California  CA   West   37253956  1257 3.37
#> 6   Colorado  CO   West    5029196    65 1.29
```

Although we have overwritten the original `murders` object, this does not change the object that loaded with `data(murders)`. If we load the `murders` data again, the original will overwrite our mutated version.



## 5.3.2 Subsetting with `filter`

Now suppose that we want to filter the data table to only show the entries for which the murder rate is lower than 0.71. To do this we use the `filter` function, which takes the **data table as the first argument** and then the **conditional statement as the second**. Like mutate, we can use the unquoted variable names from murders inside the function and it will know we mean the columns and not objects in the workspace.

> filter(data table, conditional statement)
> conditional statement : just like 'filter' function of excel. We should type the exact name of variable. 


```{r}
filter(murders, rate <= 0.71)
```



## 5.3.3 Selecting columns with `select`

Although our data table only has six columns, some data tables include hundreds. If we want to view just a few, we can use the **dplyr** `select` function. In the code below we select three columns, assign this to a new object and then filter the new object:

> purpose of `select` : select a few columns from full data frame 


```{r}
new_table <- select(murders, state, region, rate)
filter(new_table, rate<=0.71)
```

In the call to `select`, the first argument `murders` is an object, but state, region, and rate are variable names.

> select(data table, name of column #1, name of column #2, ...)


***

# 5.4 Exercises

1. Load the **dyplr** package and the muders dataset.


```{r}
library(dplyr)
library(dslabs)
data(murders)
```

You can add columns using the **dyplr** function `mutate`. This function is aware of the column names and inside the function you can call them unquoted:


```{r}
murders <- mutate(murders, population_in_millions = population / 10^6)
head(murders)
```


 We can write `population` rather than `murders$population`. The function `mutate` knows we are grabbing columns from `murders`.

 Use the function `mutate` to add a murders column named `rate` with the per 100,000 murder rate as in the example code above. Make sure you redefine `murders` as done in the example code above(murders < - [your code]) so we can keep using this variable. 
 


```{r}
murders <- mutate(murders, rate = total / population * 10^5)
head(murders)
```



2. If `rank(x)` gives you the ranks of `x` from **lowest to highest**, `rank(-x)` gives you the ranks from **highest to lowest**. Use the function mutate to add a column rank containing the rank, from highest to lowest murder rate. Make sure you redefine `murders` so we can keep using this variable.

```{r}
murders <- mutate(murders, rank = rank(-rate))
head(murders)
```

```
rank(column name) = ranks from lowest to highest
rank(-column name) = ranks from highest to lowest 
```



3. With **dplyr**, we can use `select` to show only certain columns. For example, with this code we would only show the states and population sizes:

```{r}
select(murders, state, population) %>% head()
```

```
%>% : pipe (just like in terminal)
```

Use `select` to show the state names and abbreviations in murders. Do not redefine murders, just show the results.

```{r}
select(murders, state, abb) %>% head()
```



4. The **dplyr** function `filter` is used to choose specific rows of the data frame to keep. Unlike `select` which is for columns, `filter` is for rows. For example, you can show just the New York row like this:


```{r}
filter(murders, state == "New York")
```

```
select : selecting the columns
filter : selecting the rows 
```

You can use other logical vectors to filter rows.

Use `filter` to show the top 5 states with the highest murder rates. After we add murder rate and rank, do not change the murders dataset, just show the result. Remember that you can filter based on the rank column.

```{r}
filter(murders, rank<= 5 )
```

5. We can remove rows using the `!=` operator. For example, to remove Florida, we would do this:

```{r}
no_florida <- filter(murders, state != "Florida")
```

Create a new data frame called `no_south` that removes states from the South region. How many states are in this category? You can use the function `nrow` for this.

```{r}
nrow(murders)
```

```{r}
no_south <- filter(murders, region != "South") 
nrow(no_south)
```



6. We can also use `%in%` to filter with **dplyr**. You can therefore see the data from New York and Texas like this: 

```{r}
head(filter(murders, state %in% c("New York", "Texas")))
```

Create a new data frame called `murders_nw` with only the states from the Northeast and the West. How many states are in this category? 

```{r}
murders_nw <- filter(murders, region %in% c("Northeast", "West"))
nrow(murders_nw)
```



7. Suppose you want to live in the Northeast or West **and** want the murder rate to be less than 1. We want to see the data for the states satisfying these options. Note that you can use logical operators with filter. Here is an example in which we filter to keep only small states in the Northeast region.

```{r}
filter(murders, population < 5000000 & region == "Northeast")
```

Make sure `murders` has been defined with rate and rank and still has all states. Create a table called `my_states` that contains rows for states satisfying both the conditions: it is in the Northeast or West and the murder rate is less than 1. Use `select` to show only the state name, the rate and the rank.

```{r}
my_state <- filter(murders, region %in% c("Northeast", "West") & rate < 1)
select(my_state, state, rate, rank) %>% show()
```



***

#5.5 The pipe : `%>%`

With **dplyr** we can perform a series of operations, for example select and then `filter`, by sending the results of one function to another using what is called the pipe operator: `%>%`. Some details are included below.

We wrote code above to show three variables (state, region, rate) for states that have murder rates below 0.71. To do this, we defined the intermediate object `new_table`. In **dplyr** we can write code that looks more like a description of what we want to do without intermediate objects:

<center>$original -> select -> filter$</center>

For such an operation, we can use the pip `%>%`. The code looks like this:

```{r}
murders %>% select(state, region, rate) %>% filter(rate <= 0.71)
```

This line of code is equivalent to the two lines of code above. What is going on here?

In general, the pipe sends the result of the left side of the pipe to be the first argument of the function on the right side of the pipe. Here is a very simple example:

```{r}
16 %>% sqrt()
```

We can continue to pipe values along:

```{r}
16 %>% sqrt() %>% log2()
```

The above statement is equivalent to `log2(sqrt(16))`.

Remember that the pipe sends values to the **first argument**, so we can define other arguments as if the first argument is already defined:

```{r}
16 %>% sqrt() %>% log(base=2)
```

Therefore, when using the pipe with data frames and **dplyr**, we no longer need to specify the required first argument since the **dplyr** functions we have described all take the data as the first argument. In the code we wrote:

```{r}
# first argument는 이미 선언되었다! 
murders %>% select(state, region, rate) %>% filter(rate<=0.71)
```

`murders` is the first argument of the `select` function, and the new data frame (formerly `new_table`) is the first argument of the `filter` function.

Note that the pipe works well with functions where the first argument is the input data. Functions in **tidyverse** packages like **dplyr** have this format and can be used easily with the pipe.



***

# 5.6 Exercise 

1. The pipe `%>%` can be used to perform operations sequentially without having to define intermediate objects. Start by redefining murder to include rate and rank.

```{r}
data(murders)
murders <- mutate(murders, rate = total / population * 100000, rank = rank(-rate))
```

In the solution to the previous exercise, we did the following:

```{r}
my_states <- filter(murders, region %in% c("Northeast", "West") & rate < 1)
select(my_states, state, rate, rank)
```

The pipe `%>%` permits us to perform both operations sequentially without having to define an intermediate variable `my_states`. We therefore could have mutated and selected in the same line like this:

```{r}
mutate(murders, rate =  total / population * 100000, rank = rank(-rate)) %>%
  select(state, rate, rank)
```

Notice that `select` no longer has a data frame as the first argument. The first argument is assumed to be the result of the operation conducted right before the `%>%`.

Repeat the previous exercise, but now instead of creating a new object, show the result and only include the state, rate, and rank columns. Use a pipe `%>%` to do this in just one line.

```{r}
murders %>% filter(region %in% c("Northwest", "West") & rate < 1) %>% select(state, rate, rank) 
```



2. Reset `murders` to the original table by using `data(murders)`. Use a pipe to create a new data frame called `my_states` that considers only states in the Northeast or West which have a murder rate lower than 1, and contains only the state, rate and rank columns. The pipe should also have four components separated by three `%>%`. The code should look something like this:

```{r}
#pipe로 연결된 변수를 다른 변수에 바로 저장할 수 있다.
#흥미로운 점 : 아래의 mutate에서, rate 변수가 완전히 생성되기 전에 rank 함수에서 rate를 받을 수 있다. 아무래도 함수 내에서 argument의 순서가 영향을 미치는 듯. 

data(murders)
my_states <- murders %>% 
  mutate(rate = total / population * 100000, rank = rank(-rate)) %>%
  filter(region %in% c("Northeast", "West"), rate < 1) %>%
  select(state, rate, rank)
my_states
```



*** 

# 5.7 Sorting data frames 

An important part of exploratory data analysis is **summarizing data**. The **average** and **standard deviation** are two examples of widely used summary statistics. More informative summaries can often be achieved by first splitting data into **groups**. In this section, we cover two new `dplyr` verbs that make these computations easier: `summarize` and `group_by`. We learn to access resulting values using the pull function.



## 5.7.1 `summerize`

The `summarize` function in **dplyr** provides a way to compute summary statistics with intuitive and readable code. We start with a simple example based on heights. The heights dataset includes heights and sex reported by students in an in-class survey.

```{r}
library(dplyr)
library(dslabs)
data(heights)
```

The following code computes the average and standard deviation for females:

```{r}
str(heights)
```

```{r}
s <- heights %>% 
  filter(sex == "Female") %>%
  summarize(average = mean(height), standard_deviation = sd(height))
s
```

This takes our original data table as input, filters it to keep only females, and then produces a new summarized table with just the average and the standard deviation of heights. *We get to choose the names of the columns of the resulting table.* For example, above we decided to use average and standard_deviation, but we could have used other names just the same.

Because the resulting table stored in s is a data frame, we can access the components with the accessor `$`:

```{r}
s$average
```
```{r}
s$standard_deviation
```

As with most other **dplyr** functions, `summarize` is aware of the variable names and we can use them directly. So when inside the call to the `summarize` function we write `mean(height)`, the function is accessing the column with the name “height” and then computing the average of the resulting numeric vector. 
* **dyplr**의 function들은 data_frame의 column을 자동으로 variable로 인식
We can compute any other summary that operates on vectors and returns a single value. For example, we can add the median, min and max heights like this:

```{r}
heights %>%
  filter(sex == "Female") %>%
  summarize(median = median(height), minimum = min(height), maximum = max(height))
```

We can obtain these three values with just one line using the `quantile` function: for example, `quantile(x, c(0,0.5,1))` returns the 
1) min (0th percentile),
2) median (50th percentile), and
3) max (100th percentile) of the vector x. 
* function `quantile(x,y)` : 확률변수 x에 대하여 y=probablity인 지점의 x를 return해주는 함수 
However, if we attempt to use a function like this that returns two or more values inside `summarize`:

```
heights %>%
  filter(sex == "Female") %>%
  summarize(range = quantile(height, c(0, 0.5, 1)))
```
#### error : Column `range` must be length 1 (a summary value), not 3

we will receive an error: `Error: expecting result of length one, got : 2.` With the function summarize, we can only call functions that return a single value. In Section 5.12, we will learn how to deal with functions that return more than one value.
* function `summarize`는 변수를 각각 지정해주어야 한다. (vector로 받을 수 없음)

For another example of how we can use the `summarize` function, let’s compute the average murder rate for the United States. Remember our data table includes total murders and population size for each state and we have already used **dplyr** to add a murder rate column:

```{r}
data(murders)
murders <- murders %>%
  mutate(rate = total / population * 100000)
head(murders)
```

Remember that the US murder rate is **not** the average of the state murder rates:

```{r}
summarize(murders, mean(rate))
```

This is because in the computation above the small states are given the same **weight** as the large ones. The US murder rate is the total number of murders in the US divided by the total US population. So the correct computation is:

```{r}
us_murder_rate <- murders %>%
  summarise(rate = sum(total) / sum(population) * 100000)
us_murder_rate
```

```{r}
# 사실 위의 함수에서 summarize는 별 의미 없음 
sum(murders$total) / sum(murders$population) * 100000
```
This computation counts larger states proportionally to their size which results in a larger value.



## 5.7.2 `pull`

The `us_murder_rate` object defined above represents just one number. Yet we are storing it in a data frame:

```{r}
class(us_murder_rate)
```

since, as most **dplyr** functions, `summarize` always returns a **data frame**.

This might be problematic if we want to use this result with functions that require a numeric value. Here we show a useful trick for accessing values stored in data when using `pipes`: when a data object is piped that object and its columns can be accessed using the `pull` function. To understand what we mean take a look at this line of code:

```{r}
# data_frame %>% pull(column) : date_frame의 column의 entry를 numeric으로 추출하는 함수 
us_murder_rate %>% pull(rate)
```

```{r}
murders %>% pull(population)
```

This returns the value in the rate column of `us_murder_rate` making it equivalent to `us_murder_rate$rate`.

To get a number from the original data table with one line of code we can type:

```{r}
# one-line script
us_murder_rate <- murders %>%
  summarize(rate = sum(total) / sum(population) * 100000) %>%
  pull(rate)
us_murder_rate
```

which is now a numeric:

```{r}
class(us_murder_rate)
```



## 5.7.3 Group then summarize with `group_by`

A common operation in data exploration is to first split data into groups and then compute summaries for each group. For example, we may want to compute the average and standard deviation for men’s and women’s heights separately. The group_by function helps us do this.

If we type this:

```{r}
grouped_heights <- heights %>% group_by(sex)
grouped_heights
```

```{r}
class(grouped_heights) 
```

The result does not look very different from `heights`, except we see `Groups: sex [2]` when we print the object. Although not immediately obvious from its appearance, this is now a special data frame called a *grouped data frame* and **dplyr** functions, in particular *summarize*, will behave differently when acting on this object. Conceptually, you can think of this table as many tables, with the same columns but not necessarily the same number of rows, stacked together in one object. When we summarize the data after grouping, this is what happens:

```{r}
# group_by -> summerize : 각 group 별로 나누어서 summerize 가능 
heights %>%
  group_by(sex) %>%
  summarise(average = mean(height), standard_deviation = sd(height))
```

The `summarize` function applies the summarization to each group separately.

For another example, let’s compute the median murder rate in the four regions of the country:

```{r}
murders %>%
  group_by(region) %>%
  summarize(median_rate = median(rate))
```


***

# 5.8 Sorting data frames

When examining a dataset, it is often convenient to sort the table by the different columns. We know about the `order`(순서에 대한 index return) and `sort`(순서대로 배열한 vector 자체를 return) function, but for ordering entire tables, the **dplyr** function arrange is useful. For example, here we order the states by population size:

```{r}
# function `arrange` : data_frame에서 특정 column을 오름차순 정렬
# arrange(data_frame, column) // arrange(data_frame, desc(column))
murders %>%
  arrange(population) %>%
  head()
```

With `arrange` we get to decide which column to sort by. To see the states by population, *from smallest to largest*, we arrange by `rate` instead:

```{r}
murders %>%
  arrange(rate) %>%
  head()
```

Note that the default behavior is to order in ascending order. In **dplyr**, the function desc transforms a vector so that it is in descending order. To sort the table in descending order, we can type:

```{r}
# arrange(df, desc(col)) : descending order 
murders %>%
  arrange(desc(rate)) %>%
  head()
```



## 5.8.1 Nested sorting 

If we are ordering by a column with ties, we can use a second column to break the tie. Similarly, a third column can be used to break ties between first and second and so on. 

Here we order by region, then within region we order by murder rate:

```{r}
# 1차정렬 : region, 2차정렬 : region은 묶인 채로 rate로 정렬 
# arrange(df, col1, col2, ... )
murders %>%
  arrange(region, rate) %>%
  head()
```



## 5.8.2 The top $n$

In the code above, we have used the function `head` to avoid having the page fill up with the entire dataset. If we want to see a larger proportion, we can use the `top_n` function. This function takes a data frame as it’s first argument, the number of rows to show in the second, and the variable to filter by in the third. Here is an example of how to see the top 10 rows:

```{r}
# top_n(df, #, col) : df에서 col의 top # rows를 filtering 
murders %>%
  top_n(10, rate) %>%
  arrange(rate)
```

Note that rows are not sorted by `rate`, only filtered. If want to sort, we need to use `arrange`. Note that if the third argument is left blank, `top_n`, filters by the last column.

***

# 5.9 Exercises

For these exercises, we will be using the data from the survey collected by the United States National Center for Health Statistics (NCHS). This center has conducted a series of health and nutrition surveys since the 1960’s. Starting in 1999, about 5,000 individuals of all ages have been interviewed every year and they complete the health examination component of the survey. Part of the data is made available via the **NHANES** package. Once you install the **NHANES** package, you can load the data like this:

```{r}
#install.packages("NHANES")
library("NHANES")
data(NHANES)
```

The **NHANES** data has many missing values. Remember that the main summarization function in R will return NA if any of the entries of the input vector is an NA. Here is an example:

```{r}
library(dslabs)
data("na_example")
# data에 N/A값이 있는 경우 mean, sd가 N/A만을 return
mean(na_example)
sd(na_example)
```

To ignore the NAs we can use the `na.rm` argument:

```{r}
mean(na_example, na.rm = TRUE)
```

```{r}
sd(na_example, na.rm = TRUE)
```

#> [1] 1.22
Let’s now explore the **NHANES** data.

1. We will provide some basic facts about blood pressure. First let’s select a group to set the standard. We will use 20-29 year old females. `AgeDecade` is a categorical variable with these ages. Note that the category is coded like " 20-29“, with a space in front! What is the average and standard deviation of systolic blood pressure as saved in the `BPSysAve` variable? Save it to a variable called `ref`.
Hint: Use `filter` and `summarize` and use the `na.rm = TRUE` argument when computing the average and standard deviation. You can also filter the `NA` values using `filter`.

```{r}
ref <- NHANES %>% 
  filter(AgeDecade == " 20-29" & Gender == "female") %>%
  summarize("Average" = mean(BPSysAve, na.rm=TRUE), "Standard Deviation" = sd(BPSysAve, na.rm=TRUE))

ref
``` 



2. Using a pipe, assign the average to a numeric variable `ref_avg`. 
Hint: Use the code similar to above and then `pull`.

```{r}
ref_avg <- ref %>% pull(Average)
ref_avg
```



3. Now report the min and max values for the same group.

```{r}
NHANES %>%
  filter(Gender == "female" & AgeDecade == " 20-29") %>%
  select(BPSysAve) %>%
  summarize(minimum = min(BPSysAve, na.rm = TRUE), maximum = max(BPSysAve, na.rm = TRUE))
```



4. Compute the average and standard deviation for females, but for each age group separately rather than a selected decade as in question 1. Note that the age groups are defined by AgeDecade. 
Hint: rather than filtering by age and gender, filter by Gender and then use group_by.

```{r}
NHANES %>% 
  filter(Gender == "female") %>%
  group_by(AgeDecade) %>%
  summarize("Average" = mean(BPSysAve, na.rm = TRUE), "Standard Deviation" = sd(BPSysAve, na.rm = TRUE))
```



5. Repeat exercise 4 for males.

```{r}
NHANES %>% 
  filter(Gender == "male") %>%
  group_by(AgeDecade) %>%
  summarize("Average" = mean(BPSysAve, na.rm = TRUE), "Standard Deviation" = sd(BPSysAve, na.rm = TRUE))
```



6. We can actually combine both summaries for exercises 4 and 5 into one line of code. This is because `group_by` permits us to group by more than one variable. Obtain one big summary table using `group_by(AgeDecade, Gender)`.

```{r}
NHANES %>% 
  group_by(AgeDecade, Gender) %>%
  summarize("Average" = mean(BPSysAve, na.rm = TRUE), "Standard Deviation" = sd(BPSysAve, na.rm = TRUE))
```


7. For males between the ages of 40-49, compare systolic blood pressure across race as reported in the `Race1` variable. Order the resulting table from lowest to highest average systolic blood pressure.

```{r}
NHANES %>%
  filter(Gender == 'male', AgeDecade == " 40-49") %>%
  arrange(BPSysAve) %>%
  select(Age, AgeDecade, Gender, Race1, BPSysAve)
```




***

# 5.10 Tibbles 

Tidy data must be stored in data frames. We introduced the data frame in Section 3.5 and have been using the murders data frame throughout the book:

```{r}
data(murders)
class(murders)
```

In Section 5.7.3 we introduced the `group_by` function, which permits stratifying data before computing summary statistics. But where is the group information stored in the data frame?

```{r}
murders %>%
  group_by(region) %>%
  head()
```

Notice that there are no columns with this information. But, if you look closely at the output above, you see the line `A tibble: 6 x 5`. We can learn the class of the returned object using:

```{r}
murders %>%
  group_by(region) %>%
  class()
```

The `tbl`, pronounced **tibble**, is a special kind of data frame. The functions `group_by` and `summarize` always return this type of data frame. The `group_by` function returns a special kind of `tbl`, the `grouped_df`. We will say more about these later. For consistency, the __dplyr__manipulation verbs (`select`, `filter`, `mutate`, and `arrange`) preserve the class of the input: if they receive a regular data frame they return a regular data frame, while if they receive a tibble they return a tibble. But **tibbles are the preferred format in the tidyverse** and as a result tidyverse functions that produce a data frame from scratch return a tibble. For example, in Chapter 6 we will see that tidyverse functions used to import data create tibbles.

**Tibbles** are very similar to data frames. In fact, you can think of them as a **modern version of data frames**. Nonetheless there are three important differences which we describe in the next.



# 5.10.1 Tibbles display better
 
The print method for tibbles is more readable than that of a data frame. To see this, compare the outputs of typing murders and the output of `murders` if we convert it to a tibble. We can do this using `as_tibble(murders)`. If using RStudio, **output for a tibble adjusts to your window size**. To see this, change the width of your R console and notice how more/less columns are shown.

```{r}
head(murders)
```

```{r}
head(as_tibble(murders))
```



## 5.10.2 Subsets of tibbles are tibbles 

If you subset the columns of a data frame, you may get back an object that is not a data frame, such as a vector or scalar. For example:

```{r}
murders[,4]
```
```{r}
class(murders[,4])
```

is not a data frame. With tibbles this does not happen:

```{r}
class(as_tibble(murders)[,4])
```

This is useful in the tidyverse since functions require data frames as input.

With tibbles, if you want to access the vector that defines a column, and not get back a data frame, you need to use the accessor `$`:

```{r}
class(as_tibble(murders)$population)
```

A related feature is that tibbles will give you a warning if you try to access a column that does not exist. If we accidentally write `Population` instead of `population` this:

```{r}
murders$Population
```

returns a `NULL` with no warning, which can make it harder to debug. In contrast, if we try this with a tibble we get an informative warning:

```{r}
as_tibble(murders)$Population
```



## 5.10.3 Tibbles can have complex entries

While data frame columns need to be vectors of numbers, strings or logical values, tibbles can have more complex objects, such as **lists or functions**. Also, we can create tibbles with functions:

```{r}
tibble(id = c(1,2,3), func = c(mean, median, sd))
```



## 5.10.4 Tibbles can be grouped

The function `group_by` returns a special kind of tibble: `a grouped tibble.` This class stores information that lets you know which rows are in which groups. The tidyverse functions, in particular the `summarize` function, are aware of the group information.



## 5.10.5 Create a tibble using `data_frame` instead of `data.frame`

It is sometimes useful for us to create our own data frames. To create a data frame in the tibble format, you can do this by using the `data_frame` function. (**dyplr**)

```{r}
# dyplr::data_frame
grades <- data_frame(names = c("John", "Juan", "Jean", "Yao"), 
                     exam_1 = c(95, 80, 90, 85), 
                     exam_2 = c(90, 85, 85, 90))
grades
```

Note that base R (without packages loaded) has a function with a very similar name, `data.frame`, that can be used to create a regular data frame rather than a tibble. **One other important difference is that by default `data.frame` coerces characters into factors without providing a warning or message:**

```{r}
# base::data.frame
grades <- data.frame(names = c("John", "Juan", "Jean", "Yao"), 
                     exam_1 = c(95, 80, 90, 85), 
                     exam_2 = c(90, 85, 85, 90))
class(grades$names)
```

To avoid this, we use the rather cumbersome argument `stringsAsFactors`:

```{r}
## stringAsFactors : tibble은 Factor지정을 선택할 수 있다. 
grades <- data.frame(names = c("John", "Juan", "Jean", "Yao"), 
                     exam_1 = c(95, 80, 90, 85), 
                     exam_2 = c(90, 85, 85, 90),
                     stringsAsFactors = FALSE)
class(grades$names)
```

To convert a regular data frame to a tibble, you can use the `as_tibble` function.

```{r}
as_tibble(grades) %>% class()
```



***

# 5.11 THe dot operator

One of the advantages of using the pipe `%>%` is that we do not have to keep naming new objects as we manipulate the data frame. As quick reminder, if we want to compute the median murder rate for states in the southern states, instead of typing:

```{r}
# 1. filter the rows
tab_1 <- filter(murders, region == "South")
# 2. add the rate
tab_2 <- mutate(tab_1, rate = total / population * 10^5)
rates <- tab_2$rate
median(rates)
```

We can avoid defining any new intermediate objects by instead typing:

```{r}
filter(murders, region == "South") %>%
  mutate(rate = total / population * 100000) %>%
  summarize(median = median(rate)) %>%
  pull(median)
``` 

We can do this because **each of these functions takes a data frame as the first argument.** But what if we want to access a component of the data frame. For example, what if the pull function was not available and we wanted to access `tab_2$rate`? What data frame name would we use? The answer is the **dot operator.**

For example to access the rate vector without the `pull` function we could use

```{r}
# `/$` : access certain column 
rates <- filter(murders, region == "South") %>%
  mutate(rate = total / population * 10^5) %>%
  .$rate
median(rates)
```

In the next section, we will see other instances in which using the `.` is useful.



***

# 5.12 do

* tidyverse function을 이용하여 새로운 function을 만들었을 때, 새로운 function의 input, output이 tidyverse의 rule을 따를 수 있도록 하는 방법.(tibble을 유지)

The tidyverse functions know how to interpret grouped tibbles. Furthermore, to facilitate stringing commands through the pipe `%>%`, tidyverse functions consistently return data frames, since this assures that the output of a function is accepted as the input of another. 
But most R functions do not recognize grouped tibbles nor do they return data frames. The `quantile` function is an example we described in Section 5.7.1. The `do` functions serves as a bridge between R functions such as `quantile` and the tidyverse. The `do` function understands grouped tibbles and always returns a data frame.

In Section 5.7.1, we noted that if we attempt to use `quantile` to obtain the min, median and max in one call, we will receive an `error: Error: expecting result of length one, got : 2.`

```
# summarize function은 argument를 개별적으로 받는다. 
data(heights)
heights %>% 
  filter(sex == "Female") %>%
  summarize(range = quantile(height, c(0,0.5,1)))
```
#### > Error: Column `range` must be length 1 (a summary value), not 3 

We can use the `do` function fix this.

First we have to write a function that fits into the tidyverse approach: that is, it receives a data frame and returns a data frame.

```{r}
my_summary <- function(dat){
  x <- quantile(dat$height, c(0, 0.5, 1))
  data_frame(min = x[1], mediam = x[2], max = x[3])
}
```

We can now apply the function to the heights dataset to obtain the summaries:

```{r}
heights %>% 
  group_by(sex) %>%
  my_summary 
```

But this is not what we want. We want a summary for each sex and the code returned just one summary. This is because `my_summary` is not part of the tidyverse and does not know how to handled grouped tibbles. `do` makes this connection:
* tidyverse function이 아니면 자동으로 tibble을 return하지 않는다. 

```{r}
heights %>%
  group_by(sex) %>% # make it tibble
  do(my_summary(.)) # maintain the tibble
```

Note that here we need to use the **dot operator**. The tibble created by `group_by` is piped to `do`. Within the call to `do`, the name of this tibble is `.` and we want to send it to `my_summary`. If you do not use the dot, then `my_summary` has __no argument and returns an error telling us that `argument "dat"` is missing. You can see the error by typing:

```
heights %>%
  group_by(sex) %>%
  do(my_summary())
```
#### > Error in quantile(dat$height, c(0, 0.5, 1)) : argument "dat" is missing, with no default

If you do not use the parenthesis, then the function is not executed and instead do tries to return the function. This gives an error because do must always return a data frame. You can see the error by typing:

```
heights %>% 
  group_by(sex) %>% 
  do(my_summary)
```

#### > Error: Results 1, 2 must be data frames, not function

***

# 5.13 The **purrr** package

In Section 4.5 we learned about the `sapply` function, which permitted us to apply the same function to each element of a vector. We constructed this function:

```{r}
compute_s_n <- function(n){
  x <- 1:n
  sum(x)
}
```

and used `sapply` to compute the sum of the first `n` integers for several values of `n` like this:

```{r}
# sapply : mono-numeric을 argument로 받는 함수에게 vector를 argument로 받도록 하는 방법  
n <- 1:25
s_n <- sapply(n, compute_s_n)
s_n
```

This type of operation, applying the same function or procedure to elements of an object, is quite common in data analysis. The **purrr** package includes functions similar to `sapply` but *that better interact with other tidyverse functions.* The main advantage is that we can better control the output type of functions. In contrast, `sapply` can return several different object types; for example, we might expect a numeric result from a line of code, but `sapply` might convert our result to character under some circumstances. **purrr** functions will never do this: they will return objects of a specified type or return an error if this is not possible.

The first **purrr** function we will learn is `map`, which works very similar to `sapply` but always, without exception, **returns a list**:

```{r}
library(purrr)
s_n <- map(n, compute_s_n)
class(s_n)
```

If we want a numeric vector, we can instead use `map_dbl` which always **returns a vector of numeric values.**

```{r}
s_n <- map_dbl(n, compute_s_n)
class(s_n)
```

This produces the same results as the sapply call shown above.

A particularly useful **purrr** function for interacting with the rest of the tidyverse is `map_df`, which always **returns a tibble data frame.** However, the function being called needs to return a vector a or list with names. For this reason, the following code would result in a `Argument 1 must have names error`:

```
s_n <- map_df(n, compute_s_n)
```
#### > Error: Argument 1 must have names

We need to change the function to make this work:

```{r}
compute_s_n <- function(n){
  x <- 1:n
  data_frame(sum = sum(x))
}
s_n <- map_df(n, compute_s_n)
head(s_n)
```

The purrr package provides much more functionality not covered here. For more details you can consult this [online resource](https://jennybc.github.io/purrr-tutorial/).



***

# 5.14 Tidyverse conditionals 

A typical data analysis will often involve one or more conditional operation. In Section 4.1 we described the `ifelse` function, which we will use extensively in this book. In this section we present two **dplyr** functions that provide further functionality for performing conditional operations.



## 5.14.1 `case_when`

* `ifelse`와 달리 여러 조건을 동시에 설정 가능한 `case_when`

The `case_when` function is useful for vectorizing conditional statements. It is similar to `ifelse` but can output any number of values, as opposed to just `TRUE` or `FALSE`. Here is an example splitting numbers into negative, positives and 0:

```{r}
x <- c(-2, -1, 0, 1, 2)
case_when(x < 0 ~ "Negative", x > 0 ~ "Positive", TRUE ~ "Zero")
```

A common use for this function is to define categorical variables based on existing variables. For example, suppose we want compare the murder rates in in three groups of states: New England, West Coast, South, and other. For each state, we need to ask if it is in New England, if it is not we ask if it is in the West Coast, if not we ask if it is in the South and if not we assign other. Here is how we use `case_when` to do this:

```{r}
data(murders)
murders %>% 
  mutate(group = case_when(
    abb %in% c("ME", "NH", "VT", "MA", "RI", "CT") ~ "New England",
    abb %in% c("WA", "OR", "CA") ~ "West Coast",
    region == "South" ~ "South",
    TRUE ~ "others")) %>%
  group_by(group) %>%
  summarize(rate = sum(total) / sum(population) * 10^5) %>%
  arrange(rate) #정렬
```



# 5.14.2 `between`

A common operation in data analysis is to determine if a value falls inside an interval. We can check this using conditionals. For example to check if the elements of a vector `x` are between `a` and `b` we can type

```
x >= a & x <=b
```

However, this can become cumbersome, especially within the tidyverse approach. The `between`function performs the same operation.

```
between(x, a, b)
```



***

# 5.15 Exercises 

1. Load the `murders` dataset. Which of the following is true? 

```{r}
data(murders)
str(murders)
```

A. murders is in tidy format and is stored in a tibble.

**B. murders is in tidy format and is stored in a data frame.**

C. murders is not in tidy format and is stored in a tibble.

D. murders is not in tidy format and is stored in a data frame.



2. Use `as_tibble` to covert the murders data table into a tibble and save it in an object called `murders_tibble`.

```{r}
murders_tibble <- as_tibble(murders)
```



3. Use the `group_by` function to convert murders into a tibble that is grouped by region.

```{r}
murders_tibble %>%
  group_by(region) %>%
  summarize(population = mean(population))
```



4. Write tidyverse code that is equivalent to this code: `exp(mean(log(murders$population)))`. Write it using the pipe so that each function is called without arguments. Use the dot operator to access the population. Hint: The code should start with murders `%>%`.

```{r}
exp(mean(log(murders$population)))
```

```{r}
# equivalent to `pull`
murders %>%
  .$population
```

```{r}
murders %>%
  .$population %>%
  log() %>%
  mean() %>%
  exp() 
```



5. Use the `map_df` to create a data frame with three columns named `n`, `s_n`, and `s_n_2`. The first column should contain the numbers 1 through 100. The second and third columns should each contain the sum of 1 through $n$ with $n$ the row number.

```{r}
compute_s_n <- function(n){
  x <- 1:n
  data_frame("n" = x, "s_n" = sum(x), "s_n_2" = x + sum(x))
  # 사실 s_n_2가 뭘 구하라는 건지 모르겠음... sum of through n with n the row number?? 
}

# map_df 는 dataframe의 연산 
map_df(100, compute_s_n)
```
